<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ZhouSh Blog</title>
    <description>这里是周诗蕙的个人博客</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 09 Dec 2022 10:35:03 +0800</pubDate>
    <lastBuildDate>Fri, 09 Dec 2022 10:35:03 +0800</lastBuildDate>
    <generator>Jekyll v4.3.1</generator>
    
      <item>
        <title>SLAM十四讲 3</title>
        <description>&lt;h1 id=&quot;第3讲三维空间刚体运动&quot;&gt;第3讲　三维空间刚体运动&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;内积&lt;/strong&gt;可以描述向量间的投影关系&lt;/p&gt;

&lt;p&gt;$
a\cdot b=a^Tb=\Sigma^3_{i=1}a_ib_i=|a||b|cos&amp;lt;a,b&amp;gt;
$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;外积&lt;/strong&gt;的方向垂直于这两个向量，大小为$|a||b|sin&amp;lt;a,b&amp;gt;$ ，是两个向量张成的四边形的有向面积&lt;/p&gt;

\[a\times b=\left[
\begin{matrix}
1 &amp;amp; 2 &amp;amp; 3 \\
4 &amp;amp; 5 &amp;amp; 6 \\
7 &amp;amp; 8 &amp;amp; 9 
\end{matrix} \right]\]
</description>
        <pubDate>Thu, 08 Dec 2022 17:10:00 +0800</pubDate>
        <link>http://localhost:4000/2022/12/08/SLAM14-3/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/12/08/SLAM14-3/</guid>
        
        <category>SLAM十四讲</category>
        
        
      </item>
    
      <item>
        <title>SLAM十四讲 1&amp;2</title>
        <description>&lt;h1 id=&quot;第1讲-预备知识&quot;&gt;第1讲 预备知识&lt;/h1&gt;

&lt;h2 id=&quot;11-本书讲什么&quot;&gt;1.1 本书讲什么&lt;/h2&gt;

&lt;p&gt;SLAM是Simultaneous Localization and Mapping的缩写，中文译作“同时定位与地图构建 ” 。它是指搭载特定传感器的主体，在没有环境先验信息的情况下，于运动过程中建立环境的模型，同时估计自己的运动 。如果这里的传感器主要为相机，那就称为“视觉SLAM”。&lt;/p&gt;

&lt;p&gt;目前，与SLAM相关的书籍主要有《概率机器人》（Probabilistic robotics）、《计算机视觉中的多视图几何》（Multiple View Geometry in Computer Vision）、《机器人学中的状态估计》（State Estimation for Robotics:A Matrix-Lie-Group Approach）等。&lt;/p&gt;

&lt;h2 id=&quot;12-如何使用本书&quot;&gt;1.2 如何使用本书&lt;/h2&gt;

&lt;p&gt;每一讲正文之后，我们设计了一些习题。其中，带*号的习题是具有一定难度的。我们强烈建议读者把习题都练习一遍，这对你掌握这些知识很有帮助。&lt;/p&gt;

&lt;p&gt;值得一提的是，我们只会把与解决问题相关的数学知识放在书里，并尽量保持浅显。虽然我们是工科生，但也要承认，某些做法只要经验上够用，没必要非得在数学上追求完备。只要我们知道这些算法能够工作，并且数学家们告诉了我们在什么情况下可能不工作，那么我们就表示满意，而不追究那些看似完美但实际复杂冗长的证明（当然它们固有自己的价值）。&lt;/p&gt;

&lt;p&gt;本书所有源代码均托管在&lt;a href=&quot;https://github.com/gaoxiang12/slambook&quot;&gt;github&lt;/a&gt;上。&lt;/p&gt;

&lt;p&gt;如果你不了解C++的基本知识，可以读一点C++Primer Plus 之类的图书入门。&lt;/p&gt;

&lt;p&gt;代码方面，你最好花点时间亲自输入一遍，再调节里面的参数，看看效果会发生怎样的改变。这会对学习很有帮助。&lt;/p&gt;

&lt;p&gt;我们设计的实验大多数是演示性质的。看懂了它们不代表你已经熟悉整个库的使用。所以我们建议你在课外花一点时间，对本书经常用的几个库进行深入学习。&lt;/p&gt;

&lt;p&gt;本书的习题和选读内容可能需要你自己搜索额外材料，所以你需要学会使用搜索引擎。&lt;/p&gt;

&lt;h2 id=&quot;习题&quot;&gt;习题&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/joyee512/article/details/106077304&quot;&gt;参考1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/u012348774/article/details/83576140&quot;&gt;参考2&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;第2讲-初始slam&quot;&gt;第2讲 初始SLAM&lt;/h1&gt;

&lt;h2 id=&quot;21-引子小萝卜的例子&quot;&gt;2.1 引子：小萝卜的例子&lt;/h2&gt;

&lt;p&gt;轮式编码器会测到轮子转动的角度，IMU测量运动的角速度和加速度。&lt;/p&gt;

&lt;p&gt;由于单目相机拍摄的图像只是三维空间的二维投影，所以，如果真想恢复三维结构，必须改变相机的视角。在单目SLAM中也是同样的原理。我们必须移动相机，才能估计它的运动 （Motion），同时估计场景中物体的远近和大小，不妨称之为结构（Structure）。&lt;/p&gt;

&lt;p&gt;由于单目相机拍摄的图像只是三维空间的二维投影，所以，如果真想恢复三维结构，必须改变相机的视角。在单目SLAM中也是同样的原理。我们必须移动相机，才能估计它的运动 （Motion），同时估计场景中物体的远近和大小，不妨称之为结构 （Structure）&lt;/p&gt;

&lt;p&gt;单目SLAM估计的轨迹和地图将与真实的轨迹和地图相差一个因子，也就是所谓的尺度 （Scale） 。由于单目SLAM无法仅凭图像确定这个真实尺度，所以又称为尺度不确定性 。&lt;/p&gt;

&lt;p&gt;平移之后才能计算深度，以及无法确定真实尺度，这两件事情给单目SLAM的应用造成了很大的麻烦。其根本原因是通过单张图像无法确定深度。所以，为了得到这个深度，人们开始使用双目和深度相机。&lt;/p&gt;

&lt;h2 id=&quot;23-slam问题的数学表述&quot;&gt;2.3 SLAM问题的数学表述&lt;/h2&gt;

&lt;p&gt;在离散时刻 $t=1,\cdots,K$，用x表示机器人自身的位置，记为$x_1,\cdots,x_k$。假设地图是由许多个路标（Landmark）组成的，设路标点一共有N个，则记为$y_1,\cdots,y_N$。&lt;/p&gt;

&lt;p&gt;什么是运动 ？我们要考虑从k- 1时刻到k 时刻，小萝卜的位置x 是如何变化的。&lt;/p&gt;

&lt;p&gt;什么是观测 ？假设小萝卜在k 时刻于$x_k$处探测到了某一个路标$y_j$，我们要考虑这件事情是如何用数学语言来描述的。&lt;/p&gt;

&lt;p&gt;运动方程：$x_k=f(x_{k-1},u_k.w_k)$&lt;/p&gt;

&lt;p&gt;观测方程：$z_{k,j}=h(y_j,x_k,v_{k,j})$&lt;/p&gt;

&lt;p&gt;其中$u_k$是运动传感器读数（输入），$w_k$为噪声。观测方程描述的是，当小萝卜在$x_k$位置上看到某个路标点$y_j$，产生了一个观测数据$z_{k,j}$。&lt;/p&gt;

&lt;p&gt;这两个方程描述了最基本的SLAM问题：当知道运动测量的读数u ，以及传感器的读数z时，如何求解定位问题（估计x）和建图问题（估计y）？&lt;/p&gt;

&lt;h2 id=&quot;24-编程实践&quot;&gt;2.4 编程实践&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;cmake_minimum_required(VERSION 2.8)
project(HelloSLAM)
add_executable(helloSLAM main.cpp) # 程序名，源代码
add_library(libhello libHello.cpp) # 把libHello.cpp编译成一个叫“hello”的静态库
add_library(libhello SHARED libHello.cpp) # 编译成共享库
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;在Linux中，库文件分成静态库和共享库两种 。静态库以.a作为后缀名，共享库以.so结尾。所有库都是一些函数打包后的集合，差别在于静态库每次被调用都会生成一个副本，而共享库则只有一个副本，更省空间。&lt;/p&gt;

&lt;p&gt;某程序要调用hello库时，要在生成时链接到hello库&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;add_executable(useHello main.cpp)
target_link_libraries(useHello libhello)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;习题-1&quot;&gt;习题&lt;/h2&gt;

&lt;p&gt;7.阅读&lt;a href=&quot;http://file.ncnynl.com/ros/CMake%20Practice.pdf&quot;&gt;《CMAKE实践》&lt;/a&gt;，了解cmake的其他语法。&lt;/p&gt;

&lt;p&gt;9.寻找其他cmake教学材料，深入了解cmake，例如 &lt;a href=&quot;https://github.com/TheErk/CMake-tutorial&quot;&gt;CMake-tutorial&lt;/a&gt; 。&lt;/p&gt;
</description>
        <pubDate>Thu, 08 Dec 2022 17:10:00 +0800</pubDate>
        <link>http://localhost:4000/2022/12/08/SLAM14-1-2/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/12/08/SLAM14-1-2/</guid>
        
        <category>SLAM十四讲</category>
        
        
      </item>
    
      <item>
        <title>Probabilistic Robotics Chapter2</title>
        <description>&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://gaoyichao.com/Xiaotu//resource/refs/PR.MIT.en.pdf&quot;&gt;《Probabilistic Robotics》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gaoyichao.com/Xiaotu/?book=probabilistic_robotics&amp;amp;title=index&quot;&gt;一个较好的中文翻译版（无处不在的小土）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/pptacher/probabilistic_robotics&quot;&gt;习题参考答案（github:pptacher probabilistic_robotics）&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;

&lt;h3 id=&quot;22-basic-concepts-in-probability&quot;&gt;2.2 Basic Concepts in Probability&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;假设所有随机变量都有概率密度函数（PDF，probability dendity function）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一维正态分布的PDF（高斯函数）：&lt;/p&gt;

    &lt;p&gt;$
 p(x)=(2\pi\sigma)^{-\frac{1}{2}} exp\lbrace-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}\rbrace
 $&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;多元正态分布的PDF：&lt;/p&gt;

    &lt;p&gt;$
 p(x)=det(2\pi\Sigma)^{-\frac{1}{2}} exp\lbrace-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\rbrace
 $&lt;/p&gt;

    &lt;p&gt;其中，$\mu$是平均向量，$\Sigma$是一个半正定对称矩阵，协方差。$\Sigma=\sigma^2$时，和一元正态分布函数等价&lt;/p&gt;
    &lt;blockquote&gt;
      &lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/11030459&quot;&gt;正定矩阵&lt;/a&gt;的性质类似复数中的正实数&lt;/p&gt;

      &lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E5%8D%8A%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/2152711&quot;&gt;半正定矩阵&lt;/a&gt;，设A是n阶方阵或实对称矩阵，如果对任何非零向量X，都有$X^TAX\geq0$ ，就称A为半正定矩阵&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;PDF的值不以1为上限&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;贝叶斯定律：&lt;/p&gt;

    &lt;p&gt;$
 p(x|y)=\frac{p(y|x)p(x)}{p(y)}=\eta\ p(y|x)p(x)
 $&lt;/p&gt;

    &lt;p&gt;其中$\eta$为归一化常数。如果要从y推出x，则称$p(x)$为先验分布，y为data，$p(x|y)$为后验分布&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;期望：&lt;/p&gt;

    &lt;p&gt;$
 E[X]=\sum_x x\ p(x)
 $&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;协方差：&lt;/p&gt;

    &lt;p&gt;$
 Cov[X]=E[X-E[X]]^2=E(X^2+E(X)^2-2XE(X))=E[X^2]-E[X]^2
 $&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;熵：假设x的概率为 $p(x)$，则编码x需要 $-log_2 p(x)$ 位字节&lt;/p&gt;

    &lt;p&gt;$
 H_p(x)=E[-log_2 p(x)]
 $&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;23-robot-environment-interaction&quot;&gt;2.3 Robot Environment Interaction&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;A state $x_t$ will be called $complete$ if it is the best predictor of the futrue.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;belief（包含t时刻的测量）：
 $
 bel(x_t)=p(x_t|z_{1:\ t},u_{1:\ t})
 $&lt;/p&gt;

    &lt;p&gt;belief（不包含t时刻的测量）：
 $
 \overline {bel}(x_t)=p(x_t|z_{1:\ t-1},u_{1:\ t})
 $&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;24-bayes-filters&quot;&gt;2.4 Bayes Filters&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;伪代码：$u_t$是控制，$z_t$是观测&lt;/p&gt;

    &lt;p&gt;Algorithm Bayes_filter $(bel(x_{t-1}),u_t,z_t)$:&lt;/p&gt;

    &lt;p&gt;for all $x_t$ do&lt;/p&gt;

    &lt;p&gt;$\overline {bel}(x_t)=\sum_{x_{t-1}} p(x_t|u_t,x_{t-1})bel(x_{t-1})$&lt;/p&gt;

    &lt;p&gt;${bel}(x_t)=\eta \  p(z_t|x_t) \  \overline{bel}(x_t)$&lt;/p&gt;

    &lt;p&gt;endfor&lt;/p&gt;

    &lt;p&gt;return $bel(x_t)$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;exercises&quot;&gt;Exercises&lt;/h2&gt;

&lt;h3 id=&quot;1&quot;&gt;1.&lt;/h3&gt;
&lt;p&gt;机器人雷达测量范围为0~3m，平均分布。当传感器坏时（faulty），雷达输出为小于1m。雷达坏掉的先验概率为$p=0.01$。机器人获取雷达数据N次，每次测量结果都小于1，则雷达坏掉的后验概率为？&lt;/p&gt;

&lt;p&gt;已知
$
P(X=faulty)=p=0.01, P(X=good)=1-p=0.99
$&lt;/p&gt;

&lt;p&gt;因为
$
P(X=faulty|Z_{1:n})=\eta_1 P(Z_n|X=faulty,Z_{1:n-1}) P(X=faulty|Z_{1:n-1})=\eta_1 \times 1 \times P(X=faulty|Z_{1:n-1})
$&lt;/p&gt;

&lt;p&gt;所以
$
P(X=faulty|Z_{1:n})=\eta_1 P(X=faulty|Z_{1:n-1})=\eta_2 P(X=faulty|Z_{1:n-2})=\cdots=\eta_n P(X=faulty|Z_0)=\eta_n P(X=faulty)=\eta_n p
$&lt;/p&gt;

&lt;p&gt;因为
$
P(X=good|Z_{1:n})=\eta_1 P(Z_n|X=good,Z_{1:n-1}) P(X=good|Z_{1:n-1})=\eta_1 \times \frac{1}{3} \times P(X=good|Z_{1:n-1})
$&lt;/p&gt;

&lt;p&gt;所以
$
P(X=good|Z_{1:n})=\eta_1 \frac{1}{3} P(X=good|Z_{1:n-1})=\eta_2 \frac{1}{3^2} P(X=good|Z_{1:n-2})=\cdots=\eta_n \frac{1}{3^n} P(X=good|Z_0)=\eta_n \frac{1}{3^n} P(X=good)=\eta_n \frac{1}{3^n} (1-p)
$&lt;/p&gt;

&lt;p&gt;因为
$
\eta_n p+\eta_n \frac{1}{3^n} (1-p)=1
$&lt;/p&gt;

&lt;p&gt;所以
$
\eta=\frac{1}{p+\frac{1}{3^n}(1-p)}
$&lt;/p&gt;

&lt;p&gt;所以
$
P(X=faulty|Z_{1:n})=\eta_n p=\frac{p}{p+\frac{1}{3^n}(1-p)}=\frac{0.01}{0.01+\frac{1}{3^n}\times 0.99}
$&lt;/p&gt;

&lt;p&gt;所以&lt;/p&gt;

&lt;p&gt;$
n=1,P(X=faulty|Z_1)=0.0294118;
n=2,P(X=faulty|Z_{1:2})=0.0833333;
$&lt;/p&gt;

&lt;p&gt;$
n=3,P(X=faulty|Z_{1:3})=0.214286;
n=4,P(X=faulty|Z_{1:4})=0.45;
$&lt;/p&gt;

&lt;p&gt;$
n=5,P(X=faulty|Z_{1:5})=0.710526;
n=6,P(X=faulty|Z_{1:6})=0.880435;
$&lt;/p&gt;

&lt;p&gt;$
n=7,P(X=faulty|Z_{1:7})=0.956693;
n=8,P(X=faulty|Z_{1:8})=0.956693;
$&lt;/p&gt;

&lt;p&gt;$
n=9,P(X=faulty|Z_{1:9})=0.994995;
n=10,P(X=faulty|Z_{1:10})=0.998326;
$&lt;/p&gt;

</description>
        <pubDate>Mon, 05 Dec 2022 13:47:00 +0800</pubDate>
        <link>http://localhost:4000/2022/12/05/Probabilistic-Robotics2/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/12/05/Probabilistic-Robotics2/</guid>
        
        <category>概率机器人</category>
        
        
      </item>
    
      <item>
        <title>LVI-SAM</title>
        <description>&lt;p&gt;论文：&lt;a href=&quot;https://arxiv.org/pdf/2104.10831v2.pdf&quot;&gt;LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;3D雷达、单目相机、IMU&lt;/li&gt;
  &lt;li&gt;LVI-SAM建立在&lt;strong&gt;因子图&lt;/strong&gt;上，由两个子系统组成：视觉惯性系统（VIS）和激光雷达惯性系统（LIS）&lt;/li&gt;
  &lt;li&gt;两系统紧耦合
    &lt;ul&gt;
      &lt;li&gt;VIS利用LIS初始化&lt;/li&gt;
      &lt;li&gt;LIS的深度信息帮助VIS提高视觉特征的精度&lt;/li&gt;
      &lt;li&gt;LIS利用VIS的估计结果作为扫描匹配的初始值&lt;/li&gt;
      &lt;li&gt;回环先由VIS识别，再由LIS优化&lt;/li&gt;
      &lt;li&gt;两子系统任一故障，LVI-SAM仍可以进行，从而提高无纹理无特征环境下的鲁棒性&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/img/in_post/LVI-SAM/1.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;VIS进行视觉特征跟踪，并可选用LIS提取特征的深度&lt;/li&gt;
  &lt;li&gt;VIS通过优化视觉重投影误差和IMU测量获得视觉里程计，可作为雷达扫描匹配的初始值，并将约束引入因子图&lt;/li&gt;
  &lt;li&gt;使用IMU测量值进行点云校准后，LIS将提取雷达的边和面特征，并将其与滑动窗口中的特征图进行匹配&lt;/li&gt;
  &lt;li&gt;LIS估计出的系统状态可用于VIS初始化&lt;/li&gt;
  &lt;li&gt;回环先由VIS识别候选匹配，再由LIS优化&lt;/li&gt;
  &lt;li&gt;在因子图中共同优化视觉里程计、雷达里程计、IMU预积分、闭环等约束条件&lt;/li&gt;
  &lt;li&gt;利用优化的IMU偏置项传播IMU测量值，以IMU的速率进行状态估计&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;vis&quot;&gt;VIS&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;VIS采用VINS-MONO，特征点用”Good Features To Track”，KLT稀疏光流跟踪法&lt;/li&gt;
  &lt;li&gt;初始化：首先初始化LIS获得系统状态x和b，然后根据图像时间戳将他们插入并关联到每个图像关键帧，最后使用LIS估计的x和b作为VIS的初始值&lt;/li&gt;
  &lt;li&gt;特征深度：首先将视觉特征和雷达点投影到以相机为中心的单位球体上，然后对深度点下采样至恒定密度，并用极坐标存储。对于一个视觉特征，通过极坐标搜索二维K-D树，找到球体上离该视觉特征点最近的3个深度点。特征深度就是相机中心到视觉特征，与笛卡尔空间中的3个深度点形成的平面相交的线段（如下图Depth association，特征深度为Oc到浅蓝色点的线段）。另外还需验证深度，计算3个特征点之间的特征距离，如果最大距离超过2m，则该特征点没有深度信息。
&lt;img src=&quot;/img/in_post/LVI-SAM/2.png&quot; width=&quot;90%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;回环检测：用DBoW2进行回环检测。对于每个新图像关键帧，提取BRIEF描述子，与先前的描述子进行匹配。把DBoW2返回的回环候选图像时间戳发送到LIS进行进一步验证。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;lis&quot;&gt;LIS&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/img/in_post/LVI-SAM/3.png&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;LIS采用LIO-SAM，用因子图实现全局优化&lt;/li&gt;
  &lt;li&gt;4种约束添加到图中联合优化：IMU预积分约束、视觉里程计约束、雷达里程计约束、回环约束
    &lt;ul&gt;
      &lt;li&gt;雷达约束来自扫描匹配，当前雷达关键帧和全局特征图进行匹配&lt;/li&gt;
      &lt;li&gt;回环约束由VIS提供，再由扫描匹配优化&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;初始化：初始化之前假设机器人静止，假设IMU的偏置和噪声为0，两帧雷达算出平移旋转作为初始值。初始化之后，从因子图中估计IMU偏置、机器人位姿、速度，然后发给VIS进行初始化。初始化之后可以由VIS或校正后的IMU获得初始值。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;消融实验&quot;&gt;消融实验&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/img/in_post/LVI-SAM/4.png&quot; width=&quot;70%&quot; /&gt;
&lt;img src=&quot;/img/in_post/LVI-SAM/5.png&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;该场景由于植被茂密，GPS信号差，所以在同一位置开始和结束录制数据，比较起点和终点的平移和旋转误差&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A1：VIS&lt;/li&gt;
  &lt;li&gt;A2：LIS&lt;/li&gt;
  &lt;li&gt;A3：VIS+LIS，激光为视觉提供深度信息，没有视觉回环&lt;/li&gt;
  &lt;li&gt;A4：VIS+LIS，激光为视觉提供深度信息，有视觉回环（完整系统）&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;表格中的w/o表示without，w/表示with&lt;/p&gt;

  &lt;p&gt;A1中的with depth深度信息来自于雷达，VIS并不是完全不使用雷达，详见VIS部分&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;代码&quot;&gt;代码&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ZhouShihui210/LVI-SAM_detailed_comments&quot;&gt;代码仓库&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;rviz
&lt;img src=&quot;/img/in_post/LVI-SAM/6.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;rqt_graph
&lt;img src=&quot;/img/in_post/LVI-SAM/7.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 29 Nov 2022 20:32:00 +0800</pubDate>
        <link>http://localhost:4000/2022/11/29/LVI-SAM/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/11/29/LVI-SAM/</guid>
        
        <category>SLAM</category>
        
        
      </item>
    
      <item>
        <title>cartographer</title>
        <description>&lt;p&gt;论文：&lt;a href=&quot;/doc/cartographer%20-%202016%20-%20Real%20time%20loop%20closure%20in%202D%20LIDAR%20SLAM%20-%20Hess%20et%20al.pdf&quot;&gt;Real-Time Loop Closure in 2D LIDAR SLAM&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;为了实现实时的回环检测，cartographer使用&lt;strong&gt;分支定界法&lt;/strong&gt;计算&lt;strong&gt;scan-to-map&lt;/strong&gt;匹配作为约束&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;本文的重点是减少大量数据下回环所需的&lt;strong&gt;计算量&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;related-work&quot;&gt;Related work&lt;/h2&gt;
&lt;h3 id=&quot;匹配&quot;&gt;匹配&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Scan-to-scan matching：累计漂移误差大&lt;/li&gt;
  &lt;li&gt;Scan-to-map matching：累计漂移误差小，需要好的初始值，用高斯牛顿法找局部最优值&lt;/li&gt;
  &lt;li&gt;Pixel-accurate scan matching：漂移误差小，但计算量大
    &lt;ul&gt;
      &lt;li&gt;减少计算量的策略：通过laser特征提取匹配&lt;/li&gt;
      &lt;li&gt;加强回环检测的策略：直方图统计匹配、提取laser特征、机器学习&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/12cafbd14797&quot;&gt;&lt;strong&gt;scan to scan match&lt;/strong&gt;&lt;/a&gt;：两帧激光雷达数据之间的匹配。假如当前帧的激光雷达数据为A，和它匹配的另一帧激光雷达数据为B，如果以A为起始帧，B为目标帧，那么A经过一个相对平移和旋转变换到B，我们目的就是求出这个相对平移量和旋转角度。目前来说，匹配效果最好的算法就是ICP（Iterative Closest Point）方法，它充分利用了激光雷达每个数据点来进行匹配，后来所有ICP变种基本都是为了提高计算效率而演化的，如何减小循环次数加快收敛等等。&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/12cafbd14797&quot;&gt;&lt;strong&gt;scan to map match&lt;/strong&gt;&lt;/a&gt;：即激光雷达扫描数据直接与地图进行匹配，得到实际位置坐标[x,y,theta]。这种方式一边计算位置，一边把新扫描到的数据及时加入到先前地图中。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;减少局部累计误差&quot;&gt;减少局部累计误差&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;粒子滤波：对于grid-based SLAM，占用计算资源过多&lt;/li&gt;
  &lt;li&gt;基于图优化的SLAM：node表示位姿和特征，边表示观测约束&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E7%B2%92%E5%AD%90%E6%BB%A4%E6%B3%A2/2128986&quot;&gt;&lt;strong&gt;粒子滤波&lt;/strong&gt;&lt;/a&gt;：通过寻找一组在状态空间中传播的随机样本来近似的表示概率密度函数，用样本均值代替积分运算，进而获得系统状态的最小方差估计的过程，这些样本被形象的称为“粒子”，故而叫粒子滤波。&lt;a href=&quot;https://zhuanlan.zhihu.com/p/161617286&quot;&gt;附一个非常生动的说明&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41424435&quot;&gt;&lt;strong&gt;基于图优化的SLAM&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;system-overview&quot;&gt;System overview&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/img/in_post/cartographer/system.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;将laser scan插入submap中最合适的位置，假设该位置短时间内足够准确&lt;/li&gt;
  &lt;li&gt;Scan matching针对于当前submap进行，所以只依赖于当前scan，会累积全局误差&lt;/li&gt;
  &lt;li&gt;位姿优化：
    &lt;ul&gt;
      &lt;li&gt;当submap完成后（即没有新scan插入submap），submap将进行扫描匹配以检测回环&lt;/li&gt;
      &lt;li&gt;所有结束的submap和scan会自动进行回环&lt;/li&gt;
      &lt;li&gt;If they are close enough based on current pose estimates, a scan matcher tries to find the scan in the submap.（没理解指谁和谁比较，submap不是由scan组成的吗？包含的关系还能远吗？）&lt;/li&gt;
      &lt;li&gt;若在当前估计位姿周围的搜索窗口中找到了较好匹配，则将其作为回环约束加入优化问题&lt;/li&gt;
      &lt;li&gt;软约束：回环扫描匹配需比新增scan快一些，否则会有明显滞后&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;通过branch-and-bound和子图预算栅格加速回环检测（如何实现？）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;local-2d-slam&quot;&gt;Local 2D SLAM&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;局部slam和全局slam的优化对象都是 pose（$\xi x$ , $\xi y$ , $\xi \theta$）&lt;/li&gt;
  &lt;li&gt;不平稳测量平台（如背包）需要结合IMU，获取雷达相对于重力的方向，以将scan映射到2D平面&lt;/li&gt;
  &lt;li&gt;scan matching：用非线性优化对齐scan和submap，会产生累计误差，由全局方法消除&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;a-scans&quot;&gt;A. scans&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;submap的构造是重复对齐scan和submap坐标系的迭代过程&lt;/li&gt;
  &lt;li&gt;scan坐标系—&amp;gt;submap坐标系：
&lt;img src=&quot;/img/in_post/cartographer/1.png&quot; width=&quot;60%&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;b-submaps&quot;&gt;B. submaps&lt;/h3&gt;
&lt;p&gt;（翻译成子图的话，这里的图是map而不是graph，容易产生歧义）&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;submap由几个连续的scan构建&lt;/li&gt;
  &lt;li&gt;submap采用栅格地图的形式，每格边长5cm，每格的值表示该格阻塞(有障碍物)的概率&lt;/li&gt;
  &lt;li&gt;pixel：某格点周围一圈格点&lt;/li&gt;
  &lt;li&gt;新增scan时，击中则更新击中点，为击中则更新一条射线&lt;/li&gt;
  &lt;li&gt;更新每格概率：
&lt;img src=&quot;/img/in_post/cartographer/2.png&quot; width=&quot;60%&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;c-ceres-scan-matchng&quot;&gt;C. Ceres scan matchng&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;除第一个submap外，新增scan会插入相邻两个submap&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;将scan插入submap之前，需要用基于ceres的scan matcher根据当前局部submap优化pose $\xi$ 
&lt;img src=&quot;/img/in_post/cartographer/3.png&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;$T_\xi$将$h_k$由scan坐标系变换至submap坐标系&lt;/li&gt;
  &lt;li&gt;Msmooth是平滑函数，用双三次插值减小[0，1]外点的影响&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;bicubic函数：
&lt;img src=&quot;/img/in_post/cartographer/4.png&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;closing-loops&quot;&gt;Closing loops&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;大空间通过创建许多小submap处理&lt;/li&gt;
  &lt;li&gt;用稀疏位姿矫正（SPA）来优化所有scan和submap&lt;/li&gt;
  &lt;li&gt;插入scan的相对位姿存储在内存中，将在优化回环时使用。&lt;/li&gt;
  &lt;li&gt;一旦submap结束（不再新增scan），scan和submap就进行回环检测&lt;/li&gt;
  &lt;li&gt;Scan matcher在后台运行，一旦找到好的匹配，就将相对位姿加入优化问题&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;a-optimization-problem&quot;&gt;A. Optimization problem&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;回环优化和扫描匹配一样，也是一个非线性最小二乘问题&lt;/li&gt;
  &lt;li&gt;每隔几秒，用ceres计算下述问题的解：（Sparse Pose Adjustment）
&lt;img src=&quot;/img/in_post/cartographer/5.png&quot; width=&quot;60%&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;$E_m$=$\xi_{mi}$ (i=1,…,m)是submap位姿，$E_s$=$\xi_{sj}$ (i=1,…,s)是scan位姿，在给定约束条件下进行优化&lt;/li&gt;
      &lt;li&gt;这些约束用相对位姿 $\xi_{ij}$ 和相关协方差矩阵 $\Sigma_{ij}$ 描述&lt;/li&gt;
      &lt;li&gt;对于一对submap i和scan j，位姿 $\xi_{ij}$ 描述了submap坐标系中scan匹配到的位置&lt;/li&gt;
      &lt;li&gt;此类约束的残差由下式计算：
&lt;img src=&quot;/img/in_post/cartographer/6.png&quot; width=&quot;70%&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;损失函数$\rho$（例如huber损失函数）用于减少异常值的影响。这些异常值可能出现在scan matching向优化问题SPA增加不正确的约束时，例如像办公室隔间这样的局部对称空间。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/nowgood/p/Huber-Loss.html&quot;&gt;hube loss&lt;/a&gt;: 相比于最小二乘的线性回归，HuberLoss降低了对离群点的惩罚程度。当预测偏差小于 $\delta$ 时，采用平方误差；当预测偏差大于 $\delta$ 时，采用线性误差。
&lt;img src=&quot;/img/in_post/cartographer/7.png&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;b-branch-and-bound-scan-matchingbbs&quot;&gt;B. Branch-and-bound scan matching（BBS）&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;pixel-accurate scan matching：
&lt;img src=&quot;/img/in_post/cartographer/8.png&quot; width=&quot;60%&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;W是搜索窗口，$M_{nearest}$是submap周围一圈格点&lt;/li&gt;
      &lt;li&gt;使用前面的CS公式可以提高匹配质量&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;搜索步长对效率有很大影响
    &lt;ul&gt;
      &lt;li&gt;选择角度步长 $\delta_\theta$ 使得扫描范围最大$d_{max}$处的扫描点移动不超过pixel的半径r，由余弦定理得：
&lt;img src=&quot;/img/in_post/cartographer/9.png&quot; width=&quot;60%&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;计算一个完整的步数，覆盖给定的搜索窗口（例如$W_x$=$W_y$=7m，$W_\theta$=30度），并对其取整
&lt;img src=&quot;/img/in_post/cartographer/10.png&quot; width=&quot;60%&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;产生一个有限集合W形成以估计位姿 $\xi_\theta$ 为中心的搜索窗口
&lt;img src=&quot;/img/in_post/cartographer/11.png&quot; width=&quot;70%&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;朴素的暴力搜索太慢
&lt;img src=&quot;/img/in_post/cartographer/12.png&quot; width=&quot;70%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;用Branch-and-bound分支定界法在较大搜索窗口下求解BBS问题
&lt;img src=&quot;/img/in_post/cartographer/13.png&quot; width=&quot;70%&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E5%88%86%E6%94%AF%E5%AE%9A%E7%95%8C%E6%B3%95/9902038&quot;&gt;分支定界法&lt;/a&gt;：通常，把全部可行解空间反复地分割为越来越小的子集，称为分支；并且对每个子集内的解集计算一个目标下界（对于最小值问题），这称为定界。在每次分枝后，凡是界限超出已知可行解集目标值的那些子集不再进一步分枝，这样，许多子集可不予考虑，这称剪枝。这就是分枝定界法的主要思路。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;要将分支定界法具体化，我们需要选择节点选择、分支、上界计算的方法&lt;/p&gt;

&lt;h4 id=&quot;1-node-selection&quot;&gt;1. Node selection&lt;/h4&gt;
&lt;p&gt;默认采用深度优先搜索DFS（利用栈的先进后出实现）&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;为避免加入坏匹配作为回环，引入一个分数阈值，小于阈值不予考虑。在实践中，通常不会超过阈值，这降低了节点选择和初始值的重要性。&lt;/li&gt;
  &lt;li&gt;计算每个子节点的分数上限，首先访问上限最大 最有希望的子节点
&lt;img src=&quot;/img/in_post/cartographer/14.png&quot; width=&quot;70%&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;2-branching-rule&quot;&gt;2. Branching rule&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;树上的每个节点用一组整数表示 c=（$c_x$，$c_y$，$c_\theta$，$c_h$），高度$c_h$处的节点有$2^{ch}*2^{ch}$种组合，但只表示特定的旋转。子节点的高度为$\theta$，则对应可行解。
&lt;img src=&quot;/img/in_post/cartographer/15.png&quot; width=&quot;60%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;将节点分为4个子节点&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/364015137&quot;&gt;分支&lt;/a&gt;：对一个大的步长在 x 和 y 方向进行对半拆分，而 $\theta$ 不变。对 x 和 y 都进行减半操作，相当于“分田”，在空间坐标上将搜索空间划分为四个更小的区域&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;3-computing-upper-bounds&quot;&gt;3. Computing upper bounds&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/img/in_post/cartographer/16.png&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;为了提高效率，使用预算网格图
&lt;img src=&quot;/img/in_post/cartographer/17.png&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$M_{precomp}$和$M_{nearest}$一样有pixel结构，但每个pixel存储着$2^h*2^h$大的搜索窗口中的最大值
&lt;img src=&quot;/img/in_post/cartographer/18.png&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;对于每个预算格，计算从这格开始的$2^h$宽的行的最大值。用它作为中间结果，构建下一个预算图。用这种方式，时间复杂度是O(n)，n为每个预算图中pixel个数&lt;/li&gt;
  &lt;li&gt;另一种计算上界的方式是计算分辨率较低（将分辨率依次减半）的概率栅格图，较省空间，但效果较差。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;预算图的内核思想：运动是相对的，与其遍历计算所有可能位姿对应的scan（墙），不如计算固定位姿扫描到的 ”移动“ 的墙。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;cartographer是一个2D SLAM系统，将scan-to-submap匹配回环检测和图优化相结合&lt;/li&gt;
  &lt;li&gt;单个子图轨迹由基于栅格的local SLAM建立&lt;/li&gt;
  &lt;li&gt;在后端，所有scan和submap都用pixel-accurate扫描匹配，以创建回环约束&lt;/li&gt;
  &lt;li&gt;scan和submap的约束在后端周期性进行优化&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;cartographer-代码&quot;&gt;Cartographer 代码&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/Sylviazsh/my_Graphviz/ad9664b28ac536cdc1b6400c96356e19bd959320/cartographer.svg&quot;&gt;cartographer函数关系图&lt;/a&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/Sylviazsh/my_Graphviz/ad9664b28ac536cdc1b6400c96356e19bd959320/cartographer.svg&quot; alt=&quot;cartographer函数关系图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ZhouShihui210/cartographer_detailed_comments_ws&quot;&gt;cartographer代码注释&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 28 Nov 2022 09:05:00 +0800</pubDate>
        <link>http://localhost:4000/2022/11/28/cartographer/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/11/28/cartographer/</guid>
        
        <category>SLAM</category>
        
        
      </item>
    
      <item>
        <title>围城</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;阅读时长：14h&lt;/p&gt;

  &lt;p&gt;上次读时不知所云，这次读时尤为其中修辞叹服，希望下次读时能有“感悟”&lt;/p&gt;

  &lt;p&gt;目录为原书目录，下面是摘记&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;一&quot;&gt;一&lt;/h4&gt;

&lt;p&gt;这船，倚仗人的机巧，载满人的扰攘，寄满人的希望，热闹地行着，每分钟把沾污了人气的一小方水面，还给那无情、无尽、无际的大海。&lt;/p&gt;

&lt;p&gt;这一张文凭，仿佛有亚当、夏娃下身那片树叶的功用，可以遮羞包丑；小小一方纸能把一个人的空疏、寡陋、愚笨都掩盖起来。自己没有文凭，好像精神上赤条条的，没有包裹。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;☝ 依稀记得高中时也摘抄过这句话&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;方鸿渐把这种巧妙的词句和精密的计算来抚慰自己，可是失望、遭欺骗的情欲、被损伤的骄傲，都不肯平伏，像不倒翁，捺下去又竖起来，反而摇摆得厉害。&lt;/p&gt;

&lt;h4 id=&quot;二&quot;&gt;二&lt;/h4&gt;

&lt;p&gt;喜欢中国话里夹无谓的英文字。他并无中文难达的新意，需要借英文来讲；所以他说话里嵌的英文字，还比不得嘴里嵌的金牙，因为金牙不仅妆点，尚可使用，只好比牙缝里嵌的肉屑，表示饭菜吃得好，此外全无用处。&lt;/p&gt;

&lt;h4 id=&quot;三&quot;&gt;三&lt;/h4&gt;

&lt;p&gt;她跟辛楣的长期认识并不会日积月累地成为恋爱，好比冬季每天的气候罢，你没法把今天的温度加在昨天的上面，好等明天积成个和暖的春日。&lt;/p&gt;

&lt;p&gt;出洋好比出痘子，出痧子，非出不可。小孩子出过痧痘，就可以安全长大，以后碰见这两种毛病，不怕传染。我们出过洋，也算了了一桩心愿，灵魂健全，见了博士硕士们这些微生虫，有抵抗力来自卫。&lt;/p&gt;

&lt;p&gt;慎明道：“关于Bertie离婚结婚的事，我也和他谈过。他引一句英国古话，说结婚仿佛金漆的鸟笼，笼子外面的鸟想住进去，笼内的鸟想飞出来；所以结而离，离而结，没有了局。”
苏小姐道：“法国也有这么一句话。不过，不说是鸟笼，说是被围困的城堡，城外的人想冲进去，城里的人想逃出来。”&lt;/p&gt;

&lt;p&gt;这时候，他等待他们的恭维，同时知道这恭维不会满足自己，仿佛鸦片瘾发的时候只找到一包香烟的心理。&lt;/p&gt;

&lt;p&gt;“方先生的过去太丰富了！我爱的人，我要能占领他整个生命，他在碰见我以前，没有过去，留着空白等待我。我只希望方先生前途无量。”&lt;/p&gt;

&lt;h4 id=&quot;四&quot;&gt;四&lt;/h4&gt;

&lt;p&gt;他所说的“让她三分”，不是“三分流水七分尘”的“三分”，而是“天下只有三分月色”的三分。&lt;/p&gt;

&lt;p&gt;鸿渐道：“这不是大教授干政治，这是小政客办教育。从前愚民政策是不许人民受教育，现代愚民政策是只许人民受某一种教育。不受教育的人，因为不识字，上人的当，受教育的人，因为识了字，上印刷品的当，像你们的报纸宣传品、训练干部讲义之类。”&lt;/p&gt;

&lt;h4 id=&quot;五&quot;&gt;五&lt;/h4&gt;

&lt;p&gt;“应当是杏花，表示你爱她，她不爱你；还有水仙花，表示她心肠太硬；外加艾草，表示你为了她终身痛苦。另外要配上石竹花来加重这涵意的力量。”&lt;/p&gt;

&lt;p&gt;“那最好！不要提起我，不要提起我。”鸿渐嘴里机械地说着，心里仿佛黑牢里的禁锢者摸索着一根火柴，刚划亮，火柴就熄了，眼前美看清的一片又滑回黑暗里。譬如黑夜里两条船相迎擦过，一个在这条船上，瞥见对面船舱的灯光里正是自己梦寐不忘的脸，没来得及叫唤，彼此早距离远了。这一刹那的接近，反见得暌隔的渺茫。鸿渐这时候只暗叹恨幸楣糊涂。&lt;/p&gt;

&lt;p&gt;鸿渐昨晚没睡好，今天又累了，邻室虽然弦歌交作，睡眠漆黑一团，当头罩下来，他一忽睡到天明，觉得身体里纤屑蜷伏的疲倦，都给睡眠熨平了，像衣服上的皱纹折痕经过烙铁一样。&lt;/p&gt;

&lt;p&gt;这雨愈下愈老成，水点贯串作丝，河面上像出了痘，无数麻瘢似的水涡，随生随灭，息息不停，到雨线更密，又仿佛光滑的水面上在长毛。&lt;/p&gt;

&lt;p&gt;辛楣也累得很，只怕鸿渐鼾声打搅，正在担心，没提防睡眠闷棍似的忽然一下子打他入黑暗底，滤清了梦，纯粹、完整的睡眠。&lt;/p&gt;

&lt;p&gt;鸿渐睡梦里，觉得有东西在撞这肌理稠密的睡，只破了一个小孔，而整个睡都退散了，像一道滚水似的注射冰面，醒过来只听见：“哙！哙！”。&lt;/p&gt;

&lt;p&gt;侯营长有个桔皮大鼻子，鼻子上附带一张脸，脸上应有尽有，并未给鼻子挤去眉眼，鼻尖生几个酒刺，像未熟的草莓。&lt;/p&gt;

&lt;p&gt;鸿渐想起唐小芙和自己，心像火焰的舌头突跳而起，说：“想到你还是想你？我们一天要想到不知多少人，亲戚、朋友、仇人，以及不相干的见过面的人。真正想一个人，记挂着他，希望跟他接近，这少得很。人事太忙了，不许我们全神贯注，无间断地怀念一个人。我们一生对于最亲爱的人的想念，加起来恐怕不到一刻钟，此外不过是念头在他身上瞥过，想到而已。”&lt;/p&gt;

&lt;p&gt;那天晚上，大家睡熟了还觉得饿，仿佛饿宣告独立，具体化了，跟身子分开似的。&lt;/p&gt;

&lt;p&gt;那一晚，山里的寒气把旅客们的睡眠冻得收缩，不够包裹整个身心，五人只支离零碎地睡到天明。&lt;/p&gt;

&lt;p&gt;辛楣道：“像咱们这种旅行，最试验得出一个人的品性。旅行是最劳顿，最麻烦，叫人本相毕现的时候。经过长期苦旅而彼此不讨厌的人，才可以结交作朋友——且慢，你听我说——结婚以后的蜜月旅行是次序颠倒的，应该先同旅行一个月，一个月舟车仆仆以后，双方还没有彼此看破，彼此厌恶，还没有吵嘴翻脸，还要维持原有的婚约，这种夫妇保证不会离婚。”&lt;/p&gt;

&lt;h4 id=&quot;六&quot;&gt;六&lt;/h4&gt;

&lt;p&gt;顾尔谦点头叹道：“念中国书的人，毕竟知礼，我想旁系的学生绝不会这样尊师重道的。”说完笑眯眯地望着李梅亭，这时候，上帝会懊悔没在人身上添一条能摇的狗尾巴，因此减低了不知多少表情的效果。&lt;/p&gt;

&lt;p&gt;他先出宿舍到厕所去,宿舍楼上楼下都睡得静悄悄的，脚步就像践踏在这些睡人的梦上，钉铁跟的皮鞋太重，会踏碎几个脆薄的梦。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;有好几处描写睡眠的呀，都把睡眠当作个泡泡，这泡泡有时能把人包裹其中，听不见外界吵闹，有时一戳就破，泡泡里的人就摔到床上。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;八&quot;&gt;八&lt;/h4&gt;

&lt;p&gt;睡眠这东西脾气怪得很，不要它，它偏会来，请它，哄它，千方百计勾引它，它拿身分躲得影子都不见。&lt;/p&gt;

&lt;h4 id=&quot;九&quot;&gt;九&lt;/h4&gt;

&lt;p&gt;廉耻并不廉，许多人维持它不起。&lt;/p&gt;

&lt;p&gt;房子比职业更难找。满街是屋，可是轮不到他们住。上海仿佛希望每个新来的人都像只戴壳的蜗牛，随身带着宿舍。&lt;/p&gt;

&lt;p&gt;柔嘉眼睁睁看他出了房，瘫倒在沙发里，扶头痛哭，这一阵泪不像只是眼里流的，宛如心里、整个身体里都挤出热泪合在一起宣泄。&lt;/p&gt;
</description>
        <pubDate>Sun, 27 Nov 2022 10:57:00 +0800</pubDate>
        <link>http://localhost:4000/2022/11/27/weicheng/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/11/27/weicheng/</guid>
        
        <category>摘记</category>
        
        
      </item>
    
      <item>
        <title>ORB SLAM 1</title>
        <description>&lt;p&gt;论文：&lt;a href=&quot;https://arxiv.org/pdf/1502.00956.pdf&quot;&gt;ORB-SLAM: a Versatile and Accurate Monocular SLAM System&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;对追踪、地图构建、重定位、闭环检测采用&lt;strong&gt;相同的特征&lt;/strong&gt;，使得系统更高效、简单、可靠。采用的ORB特征在没有GPU的情况下也有很好的实时性，且具有旋转不变性和光照不变性。&lt;/li&gt;
  &lt;li&gt;支持在大场景中实时运行。由于共视图（covisibility graph）的使用，特征点的跟踪与构图主要集中在局部共视区域，而与全局地图的尺寸无关。&lt;/li&gt;
  &lt;li&gt;使用一种我们称为Essential Graph的位姿图优化位姿，实现实时回环检测。它是由系统维护的生成树、闭环的链接和共视图（covisibility graph）的强边共同构建的。&lt;/li&gt;
  &lt;li&gt;实时相机重定位具有明显的旋转不变特性和光照不变性。这就使得跟踪丢失后可以恢复，增强了地图的重用性。&lt;/li&gt;
  &lt;li&gt;一种新的基于模型选择的自动和鲁棒的初始化程序，它允许创建平面和非平面场景的初始建图&lt;/li&gt;
  &lt;li&gt;提出了一种用来选择地图点和关键帧的“适者生存”方法：生成时宽松但剔除时严格。这种策略可以剔除冗余的关键帧，从而增强追踪的鲁棒性以及长时间运行的能力。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;回环和重定位方法基于他们之前提出的：Fast relocalisation and loop closing in key-frame-based SLAM&lt;/p&gt;

  &lt;p&gt;该系统的初步版本在：ORB-SALM:Tracking and mapping recognizable featrues&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/in_post/ORB-SLAM1/1.png&quot; alt=&quot;Image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;地图点和关键帧&quot;&gt;地图点和关键帧&lt;/h2&gt;
&lt;p&gt;每个地图点$p_i$存储：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;世界坐标系下3D位置$X_{wi}$&lt;/li&gt;
  &lt;li&gt;观测方向$n_i$（相机光心到观测点的方向）&lt;/li&gt;
  &lt;li&gt;ORB描述子$D_i$，它的汉明距离相对于被观察到的关键帧中的所有其他相关描述子是最小的&lt;/li&gt;
  &lt;li&gt;根据尺度不变性可以看到的该点的最大尺寸和最小尺寸$d_{min}$, $d_{max}$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每个关键帧$K_i$存储：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;相机位姿$T_{iw}$，即刚体从世界坐标系到相机坐标系的转换&lt;/li&gt;
  &lt;li&gt;相机内参，包括焦距和主点&lt;/li&gt;
  &lt;li&gt;在帧中提取的所有ORB特征&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;共视图和本质图&quot;&gt;共视图和本质图&lt;/h2&gt;

&lt;p&gt;共视图：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;无向加权图&lt;/li&gt;
  &lt;li&gt;每个节点代表一个关键帧&lt;/li&gt;
  &lt;li&gt;若两关键帧同时观测到15个地图点以上，则这2个节点用一条边相连&lt;/li&gt;
  &lt;li&gt;其共同观测到的地图点数，作为该边的权重&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本质图：&lt;/p&gt;

&lt;p&gt;位姿优化时需将回路误差进行传播，因为共视图会非常密集，所以需要包含所有节点但边更稀疏的图&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;从初始关键帧开始增量式构建一个生成树，该树提供了一个边数最少的共视图的连接子图&lt;/li&gt;
  &lt;li&gt;当插入新关键帧时，将该关键帧与树上与其有最多共同观测点的关键帧相连接&lt;/li&gt;
  &lt;li&gt;当一个关键帧被剔除时，系统将更新受该关键帧影响的连接&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本质图包含了生成树、共视图的边的子集、以及回环的边&lt;/p&gt;

&lt;h2 id=&quot;一tracking&quot;&gt;一、Tracking&lt;/h2&gt;
&lt;p&gt;作用：计算相机位姿、插入关键帧&lt;/p&gt;

&lt;p&gt;流程：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;计算初始特征和上一帧匹配，用motion-only BA优化位姿&lt;/li&gt;
  &lt;li&gt;如果跟踪失败，进行全局重定位&lt;/li&gt;
  &lt;li&gt;如果跟踪顺利，用关键帧的共可视图得出局部地图&lt;/li&gt;
  &lt;li&gt;用重投影搜索局部地图点&lt;/li&gt;
  &lt;li&gt;决定是否插入新关键帧&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;自动初始化地图：&lt;/p&gt;

&lt;p&gt;因为单目相机无法获取深度信息，就无法获取尺度信息，所以需要初始化地图。我们需要计算两帧间的位姿关系，通过三角化算出初始地图点。&lt;/p&gt;

&lt;p&gt;步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;在当前帧中寻找与参考帧匹配的特征&lt;/li&gt;
  &lt;li&gt;计算单应矩阵H和基础矩阵F&lt;/li&gt;
  &lt;li&gt;选择模型，平面用H，非平面用F&lt;/li&gt;
  &lt;li&gt;根据选择的模型计算运动，H用8点法，F用4点法&lt;/li&gt;
  &lt;li&gt;BA&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;tracking&quot;&gt;tracking&lt;/h3&gt;
&lt;p&gt;步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;提取ORB
    &lt;ul&gt;
      &lt;li&gt;在8层图像金字塔上提取FAST角点&lt;/li&gt;
      &lt;li&gt;为了确保特征点分布均匀，先将每层图像分成网格，每格提取至少5个特征点&lt;/li&gt;
      &lt;li&gt;如果某格不够提取5个，就调整检测器阈值再检测一次&lt;/li&gt;
      &lt;li&gt;根据FAST角点计算其方向和ORB特征描述子&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;通过上一帧(运动模型)估计初始位姿
    &lt;ul&gt;
      &lt;li&gt;如果跟踪成功，利用匀速运动模型估计相机位姿，对上一帧观测到的地图点进行搜索&lt;/li&gt;
      &lt;li&gt;如果跟踪失败，在上一帧地图点的基础上加大搜索范围，然后根据找到的匹配关系优化位姿&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;通过全局重定位估计初始位姿
    &lt;ul&gt;
      &lt;li&gt;如果跟踪失败，将当前帧转化为词袋(BoW)向量，在数据库中查询关键帧进行重定位&lt;/li&gt;
      &lt;li&gt;计算每个候选关键帧的ORB与地图点的对应关系&lt;/li&gt;
      &lt;li&gt;对每个候选关键帧进行RANSAC迭代，并用PnP计算当前位姿&lt;/li&gt;
      &lt;li&gt;若重定位成功，则跟踪继续进行&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;跟踪局部地图
    &lt;ul&gt;
      &lt;li&gt;局部地图包含一组关键帧$K_1$，他们和当前帧有部分共同的地图点；其中与当前帧有最多公共地图点的为参考帧$K_{ref}$&lt;/li&gt;
      &lt;li&gt;共可视图中和$K_1$相连的关键帧记为$K_2$&lt;/li&gt;
      &lt;li&gt;在当前帧中搜索$K_1$和$K_2$中的地图点：&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ol&gt;
      &lt;li&gt;计算地图点在当前帧中的投影点，若超出边缘则舍弃&lt;/li&gt;
      &lt;li&gt;计算当前观测方向和地图点平均观测方向的夹角，若小于60°则舍弃&lt;/li&gt;
      &lt;li&gt;计算地图点到相机光心的距离d，若超出尺度不变区域[$d_{min}$ , $d_{max}$]则舍弃&lt;/li&gt;
      &lt;li&gt;计算当前帧的尺度$d/d_{min}$&lt;/li&gt;
      &lt;li&gt;将地图点的描述子和当前帧中未匹配的ORB进行匹配
     - 通过当前帧的所有地图点进行位姿优化&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;插入新关键帧
    &lt;ul&gt;
      &lt;li&gt;由于相机运动，要尽可能快地插入新关键帧，回头再剔除冗余关键帧&lt;/li&gt;
      &lt;li&gt;插入新关键帧要满足以下要求：&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ol&gt;
      &lt;li&gt;距上一次全局重定位超过20帧（确保好的重定位）&lt;/li&gt;
      &lt;li&gt;局部建图处于空闲状态，或距上一关键帧超过20帧&lt;/li&gt;
      &lt;li&gt;当前帧跟踪至少50个地图点（确保好的跟踪）&lt;/li&gt;
      &lt;li&gt;当前帧与参考帧$K_{ref}$共同观测到的地图点少于90%（最小视图变换）&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;二local-mapping&quot;&gt;二、Local Mapping&lt;/h2&gt;
&lt;p&gt;作用：负责处理新的关键帧，使用局部BA对相机位姿周围环境进行优化重构&lt;/p&gt;

&lt;p&gt;流程：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;在共视图连接的所有参考帧中寻找当前帧中未匹配ORB的对应项，将之三角化为新的地图点&lt;/li&gt;
  &lt;li&gt;剔除冗余关键帧&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;步骤：&lt;/p&gt;

&lt;p&gt;对于每一帧关键帧Ki：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;插入关键帧
    &lt;ul&gt;
      &lt;li&gt;更新共视图：增加$K_i$节点，更新它和关键帧之间的边（存在共同地图点）&lt;/li&gt;
      &lt;li&gt;更新生成树&lt;/li&gt;
      &lt;li&gt;更新词袋(BoW)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;剔除最近地图点
  满足以下条件的地图点才能保留，否则剔除
    &lt;ul&gt;
      &lt;li&gt;追踪线程在预测可见该地图点的关键帧中有超过25%确实可以找到该地图点&lt;/li&gt;
      &lt;li&gt;创建地图点后，至少往后3帧都可看到该地图点&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;创建新地图点
    &lt;ul&gt;
      &lt;li&gt;在其他关键帧的未匹配ORB特征中查找$K_i$中的未匹配ORB&lt;/li&gt;
      &lt;li&gt;三角化ORB特征对后，检查是否在相机前方、视差、重投影误差、尺度一致性&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;局部BA
    &lt;ul&gt;
      &lt;li&gt;优化对象：当前帧、共视图中与其相连的关键帧、这些帧中的地图点&lt;/li&gt;
      &lt;li&gt;优化后的异常值会被删去&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;剔除局部关键帧
    &lt;ul&gt;
      &lt;li&gt;若该关键帧有90%地图点被其他3帧在相同尺度下观测到，则剔除&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;三loop-closing&quot;&gt;三、Loop Closing&lt;/h2&gt;
&lt;p&gt;作用：对每个新关键帧进行闭环搜索，检测到闭环就进行优化&lt;/p&gt;

&lt;p&gt;步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;检测候选回环
    &lt;ul&gt;
      &lt;li&gt;计算$K_i$和其共视图邻边的BoW向量，记最低分为$s_{min}$&lt;/li&gt;
      &lt;li&gt;检索数据库，舍弃分数低于$s_{min}$的关键帧&lt;/li&gt;
      &lt;li&gt;舍弃在共视图中与Ki相连的关键帧&lt;/li&gt;
      &lt;li&gt;连续检测到3帧回环才算回环&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;计算相似变换
    &lt;ul&gt;
      &lt;li&gt;计算当前帧与候选回环关键帧之间的ORB对应关系&lt;/li&gt;
      &lt;li&gt;对每个候选回环执行PANSAC迭代，用Horn方法计算相似变换&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;回环融合
    &lt;ul&gt;
      &lt;li&gt;融合重复的点，在共视图中插入与回环相关的新边&lt;/li&gt;
      &lt;li&gt;通过相似变换矫正当前帧位姿，将矫正传播到相连边，对其回环两侧&lt;/li&gt;
      &lt;li&gt;将回环关键帧及其邻帧的地图点都投影到当前帧及其邻帧上，并在投影附近小范围搜索对应匹配点，进行融合&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;本质图优化&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;代码&quot;&gt;代码&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ZhouShihui210/ORB_SLAM2&quot;&gt;ORB-SLAM2 我的代码仓库&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ZhouShihui210/my_Graphviz/c59a56268e4d8af6f7451da9ef89fd1430650150/orb_slam2/orb_slam2.svg&quot;&gt;函数关系图&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ZhouShihui210/my_Graphviz/c59a56268e4d8af6f7451da9ef89fd1430650150/orb_slam2/orb_slam2.svg&quot; alt=&quot;函数关系图&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 25 Nov 2022 14:58:00 +0800</pubDate>
        <link>http://localhost:4000/2022/11/25/ORB-SLAM1/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/11/25/ORB-SLAM1/</guid>
        
        <category>SLAM</category>
        
        
      </item>
    
      <item>
        <title>回环检测</title>
        <description>&lt;p&gt;我们可以把仅有前端和局部后端的系统称为&lt;strong&gt;VO&lt;/strong&gt;，而把带有回环检测和全局后端的系统称为&lt;strong&gt;SLAM&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;朴素的回环检测&quot;&gt;朴素的回环检测：&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;对任意两幅图像都做一遍特征匹配&lt;/li&gt;
  &lt;li&gt;随机抽取历史数据并进行回环检测&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;预计哪出可能出现回环&quot;&gt;预计哪出可能出现回环：&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;基于里程计的几何关系（Odometry based）（存在倒为因果的假设，累积误差较大时不适用）&lt;/li&gt;
  &lt;li&gt;基于外观（Appearance based）（词袋模型BoW）&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;准确率和召回率&quot;&gt;准确率和召回率&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/img/in_post/loop-closing/1.png&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;假阳性又称&lt;strong&gt;感知偏差&lt;/strong&gt;，假阴性又称&lt;strong&gt;感知变异&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;准确率：Precision=TP/(TP+FP)，描述算法提取的所有回环中确实是真实回环的概率&lt;/li&gt;
  &lt;li&gt;召回率：Recall=TP/(TP+FN)，描述在所有真实回环中被正确检测出来的概率&lt;/li&gt;
  &lt;li&gt;在SLAM中，我们对准确率的要求更高，对召回率则相对宽容（宁可放过一千，绝不错杀一个！hhh）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;词袋模型bow&quot;&gt;词袋模型BoW&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/img/in_post/loop-closing/3.png&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;用 “图像上有哪些特征” 来描述一幅图像，假设字典为[眼，鼻，口，手]，则一幅仅包含一张人脸的图像可描述为[2，1，1，0]或[1，1，1，0]（不考虑数量），与特征的空间位置和排列顺序无关&lt;/li&gt;
  &lt;li&gt;考虑到字典通用性，通常会使用一个较大规模的字典，以保证当前使用环境中的图像特征都在其中&lt;/li&gt;
  &lt;li&gt;可用k叉树来表达字典（有点像生物中的界门纲目科属种）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;k-means&quot;&gt;K-means&lt;/h3&gt;
&lt;p&gt;字典的生成问题类似一个聚类问题，可以用K-means解决，步骤如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;随机选取k个中心点&lt;/li&gt;
  &lt;li&gt;对每个样本，计算他们与每个中心点之间的距离，取最小的作为它的归类&lt;/li&gt;
  &lt;li&gt;重新计算每个类的中心点&lt;/li&gt;
  &lt;li&gt;如果每个中心点的变化很小，则算法收敛，退出；否则返回第2步重复&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;相似度计算&quot;&gt;相似度计算&lt;/h3&gt;
&lt;p&gt;我们希望对单词的区分性或重要性加以评估，给他们不同的权值以起到更好的效果。在文本检索中常用的一种做法是TF-IDF（Term Frequency-Inverse Document Frequency）。TF的思想是某单词在一幅图像中经常出现，它的区分度就高；IDF的思想是某单词在一幅图像中出现的频率越低，它的区分度越高。
&lt;img src=&quot;/img/in_post/loop-closing/2.png&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;相似性评分的处理&quot;&gt;相似性评分的处理&lt;/h3&gt;
&lt;p&gt;仅仅利用相似性不一定合适，比如办公室往往有很多同款桌椅。所以我们会先取一个先验相似度，表示某时刻关键帧图像与上以时刻关键帧的相似性，然后其他的分支都参照这个值归一化。比如说，如果当前帧与之前某关键帧的相似度超过当前帧与上一关键帧相似度的3倍，就认为可能存在回环。&lt;/p&gt;

&lt;h3 id=&quot;检测之后的验证&quot;&gt;检测之后的验证&lt;/h3&gt;
&lt;p&gt;词袋的回环检测算法完全依赖于外观而没有利用任何的几何信息，这导致外观相似的图像容易被当成回环。并且，由于词袋不在乎单词顺序，只在意单词有无的表达方式，更容易引发感知偏差。所以，在回环检测之后，我们通常还会有一个验证步骤&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;时间一致性检测&lt;/strong&gt;：设立回环的缓存机制，认为单次检测到的回环并不足以构成良好的约束，而在一段时间中一直检测到的回环，才认为是正确的回环。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;空间一致性检测&lt;/strong&gt;：对回环检测到的两个帧进行特征匹配，估计相机的运动。然后，再把运动放到之前的Pose Graph中，检查与之前的估计是否有很大的出入。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;《slam十四讲》&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 24 Nov 2022 09:05:00 +0800</pubDate>
        <link>http://localhost:4000/2022/11/24/loop-closing/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/11/24/loop-closing/</guid>
        
        <category>SLAM</category>
        
        
      </item>
    
      <item>
        <title>ORB feature</title>
        <description>&lt;p&gt;ORB特征由&lt;strong&gt;关键点&lt;/strong&gt;和&lt;strong&gt;描述子&lt;/strong&gt;两部分组成，关键点称为Oriented FAST，由FAST角点改进而来；描述子称为BRIEF（Binary Robust Independent Elementary Feature。下面先讲FAST，再介绍ORB。&lt;/p&gt;

&lt;h2 id=&quot;fast&quot;&gt;FAST&lt;/h2&gt;

&lt;p&gt;Fast是一种角点，主要检测局部像素灰度变化明显的地方，以速度快著称。步骤如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在图像中选取像素p，假设它的亮度为$I_p$&lt;/li&gt;
  &lt;li&gt;设置一个阈值T（如$I_p$的20%）&lt;/li&gt;
  &lt;li&gt;以像素p为中心，选取半径为3的圆上的16个像素点&lt;/li&gt;
  &lt;li&gt;如果选取的圆上有连续N个点亮度大于$I_p$+T或小于$I_p$-T，则像素p可被认为是特征点（N通常取9、11、12,被称为FAST-9、FAST-11、FAST-12）&lt;/li&gt;
  &lt;li&gt;循环以上4步，对每个像素执行相同操作&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;为了更高效，可添加预测试操作，以快速排除绝大多数不是角点的像素。即直接检测领域圆上的第1、5、9、13个像素的亮度，只有这4个有3个亮度大于$I_p$+T或小于$I_p$-T，才可能是一个角点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/in_post/ORB-feature/1.png&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;原始的FAST角点容易扎堆，所以在第一遍检测之后，还需要用非极大值抑制，在一定区域内仅保留最大点（ORB-SLAM中使用四叉树分裂得到更均匀的ORB分布）。&lt;/p&gt;

&lt;h3 id=&quot;fast的问题&quot;&gt;FAST的问题&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;数量：FAST角点数量很大且不确定&lt;/li&gt;
  &lt;li&gt;方向：不具有方向信息&lt;/li&gt;
  &lt;li&gt;尺度：存在尺度问题（由于固定取半径为3的圆，远看像角点的地方，接近看可能就不是角点）&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;orb&quot;&gt;ORB&lt;/h2&gt;

&lt;p&gt;针对FAST存在的问题作出改进：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;数量：指定要提取的角点数N，对FAST角点分别计算Harris相应值，选取前N个最大相应值的角点&lt;/li&gt;
  &lt;li&gt;方向：由灰度质心法（Intensity Centroid）计算旋转角，再根据旋转角旋转到统一方向&lt;/li&gt;
  &lt;li&gt;尺度：构建图像金字塔，并在金字塔的每一层上检测角点实现尺度不变性（在ORB-SLAM中）&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;oriented-fast&quot;&gt;Oriented FAST&lt;/h3&gt;

&lt;p&gt;灰度质心法：以图像块几何中心到灰度质心的向量作为特征方向&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/in_post/ORB-feature/2.png&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;steer-brief&quot;&gt;Steer BRIEF&lt;/h3&gt;

&lt;p&gt;BRIEF是一种二进制描述子，其中的0和1编码了关键点附近两个像素p和q的大小关系。p和q按照某种分布随机选取，在ORB-SLAM2源码中，写死了一种pattern，是通过神经网络的训练，发现的一种效果很好的点对pattern。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/in_post/ORB-feature/3.png&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;原始的BRIEF不具有旋转不变性，因此在图像发生旋转时容易丢失，而ORB在Oriented FAST中计算了关键点的方向，所以可以利用该方向计算旋转之后的Steer BREIED使其具有旋转不变性。即将图像块根据计算出的方向进行旋转，使得所有特征拥有统一的方向，在此基础上描述就避免了旋转带来的差异。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/in_post/ORB-feature/4.png&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;《slam十四讲》&lt;/li&gt;
  &lt;li&gt;《ORB : an efficient alternative to SIFT or SURF》&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 23 Nov 2022 09:38:00 +0800</pubDate>
        <link>http://localhost:4000/2022/11/23/ORB-feature/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/11/23/ORB-feature/</guid>
        
        <category>SLAM</category>
        
        
      </item>
    
      <item>
        <title>Welcome to Jekyll!</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;“Yeah It’s on. ”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You’ll find this post in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;Jekyll requires blog post files to be named according to the following format:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YEAR-MONTH-DAY-title.MARKUP&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YEAR&lt;/code&gt; is a four-digit number, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MONTH&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAY&lt;/code&gt; are both two-digit numbers, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MARKUP&lt;/code&gt; is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Mon, 21 Nov 2022 22:03:00 +0800</pubDate>
        <link>http://localhost:4000/2022/11/21/welcome-to-jekyll/</link>
        <guid isPermaLink="true">http://localhost:4000/2022/11/21/welcome-to-jekyll/</guid>
        
        <category>教程</category>
        
        
      </item>
    
  </channel>
</rss>
